{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d78cf62e-7d13-4a1b-9f49-738c3ff6f00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Requirement already satisfied: transformers in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abeya\\anaconda3\\envs\\tf_gp\\lib\\site-packages (from requests->transformers) (2024.8.30)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "666ac4fc-cd87-49d4-9caf-bee5132d502c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abeya\\anaconda3\\envs\\summ_env\\lib\\site-packages\\torch\\_subclasses\\functional_tensor.py:295: UserWarning: Failed to initialize NumPy: DLL load failed while importing _multiarray_umath: The specified module could not be found. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n",
      "C:\\Users\\abeya\\anaconda3\\envs\\summ_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "159c8d05-5fa0-4078-a700-ffa6f56c0bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SummarizationDataset(Dataset):\n",
    "    def __init__(self, articles_folder, summaries_folder, tokenizer, max_length):\n",
    "        self.articles_folder = articles_folder\n",
    "        self.summaries_folder = summaries_folder\n",
    "        self.file_list = os.listdir(articles_folder)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.file_list[idx]\n",
    "        article_path = os.path.join(self.articles_folder, file_name)\n",
    "        summary_path = os.path.join(self.summaries_folder, file_name)\n",
    "\n",
    "        with open(article_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            article = f.read()\n",
    "\n",
    "        with open(summary_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            summary = f.read()\n",
    "\n",
    "        inputs = self.tokenizer(\n",
    "            article,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        labels = self.tokenizer(\n",
    "            summary,\n",
    "            max_length=self.max_length // 2,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": inputs[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": inputs[\"attention_mask\"].squeeze(0),\n",
    "            \"labels\": labels[\"input_ids\"].squeeze(0),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "483cf17f-fe0f-4513-99ea-dae1b1df21e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "articles_folder = r\"C:\\Users\\abeya\\OneDrive\\Desktop\\Summ_implementation\\pmtexts\"\n",
    "summaries_folder = r\"C:\\Users\\abeya\\OneDrive\\Desktop\\Summ_implementation\\pmabstract\"\n",
    "\n",
    "# Tokenizer and Dataset\n",
    "model_name = \"google/bigbird-pegasus-large-arxiv\"\n",
    "max_length = 1024\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, model_max_length=max_length)\n",
    "\n",
    "dataset = SummarizationDataset(articles_folder, summaries_folder, tokenizer, max_length)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35cfbcb-8576-4897-ae80-10ecbe848924",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df10ad11-bfcb-44f7-bf6f-187db71aadbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/5: 100%|██████████| 86/86 [1:07:41<00:00, 47.22s/it, Loss=7.9178] \n",
      "Epoch 2/5: 100%|██████████| 86/86 [1:03:08<00:00, 44.05s/it, Loss=7.0461]\n",
      "Epoch 3/5: 100%|██████████| 86/86 [56:16<00:00, 39.26s/it, Loss=5.8017]\n",
      "Epoch 4/5: 100%|██████████| 86/86 [56:51<00:00, 39.67s/it, Loss=3.4823]\n",
      "Epoch 5/5: 100%|██████████| 86/86 [1:00:24<00:00, 42.14s/it, Loss=3.5326]\n",
      "C:\\Users\\abeya\\anaconda3\\envs\\summ_env\\lib\\site-packages\\transformers\\modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256, 'num_beams': 5, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Optimization settings\n",
    "num_epochs = 5\n",
    "learning_rate = 2e-5\n",
    "accumulation_steps = 4  \n",
    "\n",
    "# Initialize optimizer with weight decay\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "steps_per_epoch = max(1, len(dataloader) // accumulation_steps)  # Ensure it's at least 1\n",
    "\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "    optimizer,\n",
    "    max_lr=learning_rate,\n",
    "    epochs=num_epochs,\n",
    "    steps_per_epoch=steps_per_epoch\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Training loop with optimizations\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    progress_bar = tqdm(enumerate(dataloader), total=len(dataloader), desc=f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    for i, batch in progress_bar:\n",
    "        # Transfer batch to device\n",
    "        input_ids = batch[\"input_ids\"].to(device, non_blocking=True)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device, non_blocking=True)\n",
    "        labels = batch[\"labels\"].to(device, non_blocking=True)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss / accumulation_steps \n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Gradient accumulation\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        \n",
    "        progress_bar.set_postfix({\"Loss\": f\"{loss.item() * accumulation_steps:.4f}\"})\n",
    "\n",
    "# Save model and tokenizer\n",
    "output_dir = r\"C:\\Users\\abeya\\OneDrive\\Desktop\\Summ_implementation\\mod_out17\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "print(\"Model and tokenizer saved!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c0312a0-979f-4024-b5eb-5277a273dc7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text2 =  \"\"\"BACKGROUND\n",
    "micrornas  are a class of small non-coding rnas that regulate gene expression by binding to their target mrnas and triggering either protein translation repression or rna degradation  <cit> . recent studies show that some mirnas are located at fragile sites and genomic regions involved in cancers  <cit> . the aberrant expression of mirna genes could lead to human disease, including cancer  <cit> , and are regarded as potential biomarkers for cancer diagnosis  <cit> . the roles mirnas play have been demonstrated in a few cancer types including breast cancer  <cit> , lung cancer  <cit>  and chronic lymphocytic leukemia  <cit> , while the roles of mirna in other cancers remain largely unknown.\n",
    "\n",
    "there are several approaches of studying mirnas and their expression profiles, including northern blotting and real-time pcr assay. there are also available high-throughput methods such as oligonucleotide mirna microarray analysis  <cit> , bead-based flow-cytometric technique  <cit> , and sage-based mirage  <cit> . mirna microarray analysis is a commonly used high-throughput technique for the assessment of previously discovered mirnas. with the sage-based technique, such as mirage, the expression profiles of known mirnas could be retrieved together with the unknown ones which are possible mirna candidates.\n",
    "\n",
    "for gene expression sage studies  <cit> , there exist several well developed methods for data analysis together with web services provided, such as sagemap  <cit>  and sage genie  <cit> . for mirna-related sage, however, the data analysis is much more complicated. the extracted tags have to be compared with various rna databases in addition to mrna sequences. the tags also need to be mapped to the human genome and to be analyzed for precursors with thermodynamically stable hairpin structures. this is a very troublesome process and current users have to refer to several different databases to retrieve related biologically significant data  <cit> . to aid the processing and data analysis of this method, we constructed a web-based system, named mirna analysis system . the expression profile of known mirnas in submitted sequences were returned and compared with public dataset using fisher's exact test. public available datasets of known mirnas expression in liver were collected for the annotation of mirna expression in liver. several public available gene expression datasets were included to reveal differentially expressed genes in liver cancer and normal liver tissues. the differentially expressed mirnas and genes are highlighted and the relationship between mirnas and genes is shown according to mirna target prediction.\n",
    "\n",
    "RESULTS\n",
    "users could upload the raw sequencing data and specify the sequencing parameters through the web interface. the known mirnas and possible mirna candidates will be analyzed together with their expression profiles. the target genes predicted by mirna target prediction software are provided together with the annotation information. to demonstrate the biological significance of the retrieved mirnas, the profiles of public datasets of known mirnas and target genes were collected and included in the annotation.\n",
    "\n",
    "the miras system provides an easy and friendly way for scientists to analyze and process raw mirna sequence data to obtain new mirna candidates. it also provides tools for the annotations of the predicted mirnas.\n",
    "\n",
    "CONCLUSIONS\n",
    "in this work, we established a web-based analysis platform for mirnas, called miras  <cit> , to analyze the mirna expression in specific tissue and to predict and study the possible mirna candidates. the differentially expressed mirnas that target differentially expressed genes are retrieved together with mirna and target gene annotation, to uncover the biological significance. currently it supports liver cancer genes, while in the future, the analysis platform is planned to be expanded to support other cancers and to integrate all public available expression data of the mirnas and genes in cancer and normal tissues.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24a0653d-318d-4111-9b88-3673451f8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"C:\\Users\\abeya\\OneDrive\\Desktop\\Summ_implementation\\mod_out17\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d63a5470-4a42-46e4-a00d-c19b8c442a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 797 to 832 to be a multiple of `config.block_size`: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "expression data of micrornas ( mirnas ) are a class of small non -coding rnas that regulate gene expression by binding to their target mrnas and triggering either protein translation repression or rna degradation .<n> recent studies show that some mirnas are located at fragile sites and genomic regions involved in cancers , and are regarded as potential biomarkers for cancer diagnosis . in this work , we established a web - based system , named mirna analysis system , to analyze the expression profiles of known mirnas and to predict and study the possible mirna candidates .<n> the differentially expressed mirnas and genes were retrieved together with mirna and target gene annotation to uncover the biological significance . to aid the processing and data analysis of the retrieved mirna sequences , the profiles of known mirnas and target genes were collected and included in the annotation miras system .\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "device = torch.device(\"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(output_dir).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# Generate summary for test input\n",
    "test_text = sample_text2\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], max_length=512, min_length=100)\n",
    "\n",
    "print(\"Generated Summary:\")\n",
    "print(tokenizer.decode(summary_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "962a72fb-a126-45c2-9437-e02f493a1bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigBirdPegasusForConditionalGeneration(\n",
      "  (model): BigBirdPegasusModel(\n",
      "    (shared): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
      "    (encoder): BigBirdPegasusEncoder(\n",
      "      (embed_tokens): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
      "      (embed_positions): BigBirdPegasusLearnedPositionalEmbedding(4096, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-15): 16 x BigBirdPegasusEncoderLayer(\n",
      "          (self_attn): BigBirdPegasusEncoderAttention(\n",
      "            (self): BigBirdPegasusBlockSparseAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (output): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): NewGELUActivation()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): BigBirdPegasusDecoder(\n",
      "      (embed_tokens): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
      "      (embed_positions): BigBirdPegasusLearnedPositionalEmbedding(4096, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-15): 16 x BigBirdPegasusDecoderLayer(\n",
      "          (self_attn): BigBirdPegasusDecoderAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (activation_fn): NewGELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BigBirdPegasusDecoderAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "device = torch.device(\"cpu\")\n",
    "model2 = AutoModelForSeq2SeqLM.from_pretrained(output_dir).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "print(model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9b0c8c5-3b6c-497c-8fc4-87465f88fa19",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, Loss: 9.7796\n",
      "Epoch 1/3, Loss: 9.6340\n",
      "Epoch 1/3, Loss: 7.9094\n",
      "Epoch 1/3, Loss: 9.3209\n",
      "Epoch 1/3, Loss: 8.6479\n",
      "Epoch 1/3, Loss: 8.5033\n",
      "Epoch 1/3, Loss: 9.1245\n",
      "Epoch 1/3, Loss: 6.0807\n",
      "Epoch 1/3, Loss: 6.8284\n",
      "Epoch 1/3, Loss: 9.0147\n",
      "Epoch 1/3, Loss: 8.5330\n",
      "Epoch 1/3, Loss: 10.2837\n",
      "Epoch 1/3, Loss: 7.7836\n",
      "Epoch 1/3, Loss: 10.3661\n",
      "Epoch 1/3, Loss: 7.9583\n",
      "Epoch 1/3, Loss: 7.3588\n",
      "Epoch 1/3, Loss: 8.8226\n",
      "Epoch 1/3, Loss: 6.5705\n",
      "Epoch 1/3, Loss: 7.8581\n",
      "Epoch 1/3, Loss: 8.0010\n",
      "Epoch 1/3, Loss: 7.8379\n",
      "Epoch 1/3, Loss: 6.9810\n",
      "Epoch 1/3, Loss: 7.0189\n",
      "Epoch 1/3, Loss: 5.7712\n",
      "Epoch 1/3, Loss: 6.1234\n",
      "Epoch 1/3, Loss: 7.4748\n",
      "Epoch 1/3, Loss: 7.2503\n",
      "Epoch 1/3, Loss: 7.2808\n",
      "Epoch 1/3, Loss: 8.1749\n",
      "Epoch 1/3, Loss: 6.4271\n",
      "Epoch 1/3, Loss: 9.0498\n",
      "Epoch 1/3, Loss: 6.6214\n",
      "Epoch 1/3, Loss: 7.2302\n",
      "Epoch 1/3, Loss: 7.3719\n",
      "Epoch 1/3, Loss: 7.0062\n",
      "Epoch 1/3, Loss: 7.0565\n",
      "Epoch 1/3, Loss: 7.3765\n",
      "Epoch 1/3, Loss: 8.0411\n",
      "Epoch 1/3, Loss: 6.9570\n",
      "Epoch 1/3, Loss: 6.2664\n",
      "Epoch 1/3, Loss: 6.7050\n",
      "Epoch 1/3, Loss: 7.6048\n",
      "Epoch 1/3, Loss: 6.0565\n",
      "Epoch 1/3, Loss: 6.8897\n",
      "Epoch 1/3, Loss: 6.2488\n",
      "Epoch 1/3, Loss: 5.7250\n",
      "Epoch 1/3, Loss: 6.3916\n",
      "Epoch 1/3, Loss: 5.5473\n",
      "Epoch 1/3, Loss: 5.4389\n",
      "Epoch 1/3, Loss: 5.8217\n",
      "Epoch 1/3, Loss: 7.2152\n",
      "Epoch 1/3, Loss: 5.7880\n",
      "Epoch 1/3, Loss: 4.7517\n",
      "Epoch 1/3, Loss: 5.4317\n",
      "Epoch 1/3, Loss: 4.7515\n",
      "Epoch 1/3, Loss: 4.6379\n",
      "Epoch 1/3, Loss: 4.5891\n",
      "Epoch 1/3, Loss: 5.1521\n",
      "Epoch 1/3, Loss: 5.2413\n",
      "Epoch 1/3, Loss: 4.3411\n",
      "Epoch 1/3, Loss: 5.4793\n",
      "Epoch 1/3, Loss: 4.3939\n",
      "Epoch 1/3, Loss: 4.3947\n",
      "Epoch 1/3, Loss: 4.2688\n",
      "Epoch 1/3, Loss: 5.6896\n",
      "Epoch 1/3, Loss: 3.5600\n",
      "Epoch 1/3, Loss: 4.0045\n",
      "Epoch 1/3, Loss: 3.3382\n",
      "Epoch 1/3, Loss: 3.7518\n",
      "Epoch 1/3, Loss: 3.3744\n",
      "Epoch 1/3, Loss: 3.6536\n",
      "Epoch 1/3, Loss: 2.8195\n",
      "Epoch 1/3, Loss: 4.3251\n",
      "Epoch 1/3, Loss: 3.5945\n",
      "Epoch 1/3, Loss: 2.8088\n",
      "Epoch 1/3, Loss: 3.0427\n",
      "Epoch 1/3, Loss: 2.2433\n",
      "Epoch 1/3, Loss: 2.2992\n",
      "Epoch 1/3, Loss: 2.2740\n",
      "Epoch 1/3, Loss: 2.0742\n",
      "Epoch 1/3, Loss: 1.9604\n",
      "Epoch 1/3, Loss: 2.9293\n",
      "Epoch 1/3, Loss: 1.9230\n",
      "Epoch 1/3, Loss: 1.8169\n",
      "Epoch 1/3, Loss: 2.4124\n",
      "Epoch 1/3, Loss: 3.0116\n",
      "Epoch 2/3, Loss: 2.4615\n",
      "Epoch 2/3, Loss: 1.8570\n",
      "Epoch 2/3, Loss: 1.5414\n",
      "Epoch 2/3, Loss: 2.3461\n",
      "Epoch 2/3, Loss: 1.8756\n",
      "Epoch 2/3, Loss: 1.7720\n",
      "Epoch 2/3, Loss: 1.3318\n",
      "Epoch 2/3, Loss: 2.8913\n",
      "Epoch 2/3, Loss: 1.6768\n",
      "Epoch 2/3, Loss: 1.1965\n",
      "Epoch 2/3, Loss: 1.2509\n",
      "Epoch 2/3, Loss: 2.9627\n",
      "Epoch 2/3, Loss: 1.5409\n",
      "Epoch 2/3, Loss: 1.6223\n",
      "Epoch 2/3, Loss: 1.8356\n",
      "Epoch 2/3, Loss: 1.1365\n",
      "Epoch 2/3, Loss: 1.4846\n",
      "Epoch 2/3, Loss: 0.9630\n",
      "Epoch 2/3, Loss: 1.6071\n",
      "Epoch 2/3, Loss: 1.8463\n",
      "Epoch 2/3, Loss: 1.1355\n",
      "Epoch 2/3, Loss: 1.6350\n",
      "Epoch 2/3, Loss: 1.8042\n",
      "Epoch 2/3, Loss: 1.3558\n",
      "Epoch 2/3, Loss: 1.0221\n",
      "Epoch 2/3, Loss: 1.7097\n",
      "Epoch 2/3, Loss: 1.5380\n",
      "Epoch 2/3, Loss: 1.2270\n",
      "Epoch 2/3, Loss: 0.8961\n",
      "Epoch 2/3, Loss: 2.5383\n",
      "Epoch 2/3, Loss: 1.2093\n",
      "Epoch 2/3, Loss: 1.6118\n",
      "Epoch 2/3, Loss: 1.2534\n",
      "Epoch 2/3, Loss: 1.0754\n",
      "Epoch 2/3, Loss: 1.0336\n",
      "Epoch 2/3, Loss: 1.7776\n",
      "Epoch 2/3, Loss: 1.8469\n",
      "Epoch 2/3, Loss: 1.3586\n",
      "Epoch 2/3, Loss: 2.6048\n",
      "Epoch 2/3, Loss: 0.9991\n",
      "Epoch 2/3, Loss: 3.4063\n",
      "Epoch 2/3, Loss: 1.2478\n",
      "Epoch 2/3, Loss: 1.1502\n",
      "Epoch 2/3, Loss: 2.2077\n",
      "Epoch 2/3, Loss: 1.4407\n",
      "Epoch 2/3, Loss: 1.2066\n",
      "Epoch 2/3, Loss: 1.4680\n",
      "Epoch 2/3, Loss: 2.3373\n",
      "Epoch 2/3, Loss: 1.7333\n",
      "Epoch 2/3, Loss: 1.4593\n",
      "Epoch 2/3, Loss: 1.3407\n",
      "Epoch 2/3, Loss: 1.2139\n",
      "Epoch 2/3, Loss: 2.0586\n",
      "Epoch 2/3, Loss: 1.2530\n",
      "Epoch 2/3, Loss: 0.9279\n",
      "Epoch 2/3, Loss: 1.2015\n",
      "Epoch 2/3, Loss: 2.0740\n",
      "Epoch 2/3, Loss: 2.2530\n",
      "Epoch 2/3, Loss: 0.5776\n",
      "Epoch 2/3, Loss: 1.1478\n",
      "Epoch 2/3, Loss: 1.3287\n",
      "Epoch 2/3, Loss: 1.0523\n",
      "Epoch 2/3, Loss: 1.6838\n",
      "Epoch 2/3, Loss: 1.6821\n",
      "Epoch 2/3, Loss: 2.3015\n",
      "Epoch 2/3, Loss: 1.0299\n",
      "Epoch 2/3, Loss: 1.1854\n",
      "Epoch 2/3, Loss: 1.1250\n",
      "Epoch 2/3, Loss: 0.9546\n",
      "Epoch 2/3, Loss: 1.4433\n",
      "Epoch 2/3, Loss: 0.7576\n",
      "Epoch 2/3, Loss: 1.3436\n",
      "Epoch 2/3, Loss: 1.2925\n",
      "Epoch 2/3, Loss: 1.1402\n",
      "Epoch 2/3, Loss: 1.4077\n",
      "Epoch 2/3, Loss: 1.6721\n",
      "Epoch 2/3, Loss: 1.4290\n",
      "Epoch 2/3, Loss: 1.0435\n",
      "Epoch 2/3, Loss: 1.9678\n",
      "Epoch 2/3, Loss: 1.2868\n",
      "Epoch 2/3, Loss: 0.6992\n",
      "Epoch 2/3, Loss: 1.0518\n",
      "Epoch 2/3, Loss: 1.7168\n",
      "Epoch 2/3, Loss: 1.2138\n",
      "Epoch 2/3, Loss: 1.3829\n",
      "Epoch 2/3, Loss: 0.9357\n",
      "Epoch 3/3, Loss: 0.8476\n",
      "Epoch 3/3, Loss: 1.0347\n",
      "Epoch 3/3, Loss: 1.4163\n",
      "Epoch 3/3, Loss: 1.3577\n",
      "Epoch 3/3, Loss: 1.5925\n",
      "Epoch 3/3, Loss: 1.2911\n",
      "Epoch 3/3, Loss: 1.2337\n",
      "Epoch 3/3, Loss: 1.1124\n",
      "Epoch 3/3, Loss: 1.3652\n",
      "Epoch 3/3, Loss: 1.5721\n",
      "Epoch 3/3, Loss: 1.8674\n",
      "Epoch 3/3, Loss: 1.0769\n",
      "Epoch 3/3, Loss: 1.6105\n",
      "Epoch 3/3, Loss: 1.6556\n",
      "Epoch 3/3, Loss: 0.9364\n",
      "Epoch 3/3, Loss: 0.7753\n",
      "Epoch 3/3, Loss: 2.2536\n",
      "Epoch 3/3, Loss: 1.3932\n",
      "Epoch 3/3, Loss: 1.0189\n",
      "Epoch 3/3, Loss: 1.0808\n",
      "Epoch 3/3, Loss: 1.1055\n",
      "Epoch 3/3, Loss: 1.1462\n",
      "Epoch 3/3, Loss: 1.0563\n",
      "Epoch 3/3, Loss: 0.5989\n",
      "Epoch 3/3, Loss: 2.1757\n",
      "Epoch 3/3, Loss: 1.5188\n",
      "Epoch 3/3, Loss: 1.4499\n",
      "Epoch 3/3, Loss: 1.1137\n",
      "Epoch 3/3, Loss: 1.1688\n",
      "Epoch 3/3, Loss: 1.1077\n",
      "Epoch 3/3, Loss: 0.9784\n",
      "Epoch 3/3, Loss: 1.3413\n",
      "Epoch 3/3, Loss: 1.8972\n",
      "Epoch 3/3, Loss: 1.2487\n",
      "Epoch 3/3, Loss: 1.6747\n",
      "Epoch 3/3, Loss: 1.5028\n",
      "Epoch 3/3, Loss: 0.8993\n",
      "Epoch 3/3, Loss: 1.0263\n",
      "Epoch 3/3, Loss: 1.4782\n",
      "Epoch 3/3, Loss: 0.6640\n",
      "Epoch 3/3, Loss: 1.0157\n",
      "Epoch 3/3, Loss: 0.9593\n",
      "Epoch 3/3, Loss: 0.6923\n",
      "Epoch 3/3, Loss: 1.6495\n",
      "Epoch 3/3, Loss: 1.6816\n",
      "Epoch 3/3, Loss: 2.2596\n",
      "Epoch 3/3, Loss: 1.2051\n",
      "Epoch 3/3, Loss: 1.1270\n",
      "Epoch 3/3, Loss: 1.3254\n",
      "Epoch 3/3, Loss: 1.0154\n",
      "Epoch 3/3, Loss: 2.0200\n",
      "Epoch 3/3, Loss: 0.6718\n",
      "Epoch 3/3, Loss: 0.9845\n",
      "Epoch 3/3, Loss: 0.7791\n",
      "Epoch 3/3, Loss: 0.6268\n",
      "Epoch 3/3, Loss: 0.6061\n",
      "Epoch 3/3, Loss: 1.1916\n",
      "Epoch 3/3, Loss: 1.1758\n",
      "Epoch 3/3, Loss: 1.6172\n",
      "Epoch 3/3, Loss: 1.3949\n",
      "Epoch 3/3, Loss: 2.2112\n",
      "Epoch 3/3, Loss: 1.5476\n",
      "Epoch 3/3, Loss: 0.6603\n",
      "Epoch 3/3, Loss: 0.7044\n",
      "Epoch 3/3, Loss: 0.8460\n",
      "Epoch 3/3, Loss: 1.1022\n",
      "Epoch 3/3, Loss: 1.4146\n",
      "Epoch 3/3, Loss: 1.7996\n",
      "Epoch 3/3, Loss: 0.8823\n",
      "Epoch 3/3, Loss: 1.0382\n",
      "Epoch 3/3, Loss: 1.1697\n",
      "Epoch 3/3, Loss: 1.0059\n",
      "Epoch 3/3, Loss: 1.0773\n",
      "Epoch 3/3, Loss: 0.9019\n",
      "Epoch 3/3, Loss: 1.2498\n",
      "Epoch 3/3, Loss: 0.7509\n",
      "Epoch 3/3, Loss: 1.5388\n",
      "Epoch 3/3, Loss: 0.5748\n",
      "Epoch 3/3, Loss: 1.8106\n",
      "Epoch 3/3, Loss: 1.0910\n",
      "Epoch 3/3, Loss: 1.0114\n",
      "Epoch 3/3, Loss: 0.6605\n",
      "Epoch 3/3, Loss: 1.6213\n",
      "Epoch 3/3, Loss: 1.5101\n",
      "Epoch 3/3, Loss: 0.8849\n",
      "Epoch 3/3, Loss: 1.5301\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "num_epochs = 3\n",
    "learning_rate = 2e-5\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "089947ef-75dc-4876-93f6-5e25c31d9fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\abeya\\anaconda3\\envs\\summ_env\\lib\\site-packages\\transformers\\modeling_utils.py:2817: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256, 'num_beams': 5, 'length_penalty': 0.8}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer saved!\n"
     ]
    }
   ],
   "source": [
    "output_dir = r\"C:\\Users\\abeya\\OneDrive\\Desktop\\Summ_implementation\\mod_out7\"\n",
    "model.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)\n",
    "\n",
    "print(\"Model and tokenizer saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5f5adc1-5449-452a-970e-556951fd9b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = r\"C:\\Users\\abeya\\OneDrive\\Desktop\\Summ_implementation\\mod_out7\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f72a0627-0d89-449f-acd6-9999a94840b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Input ids are automatically padded from 797 to 832 to be a multiple of `config.block_size`: 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Summary:\n",
      "expression data of micrornas ( mirnas ) are a class of small non-coding rnas that regulate gene expression by binding to their target mrnas and triggering either protein translation repression or rna degradation cit>. the differentially expressed mirnas and genes are retrieved together with mirna and target gene annotation , to uncover the biological significance . in this work , we established a web - based system , named mirna analysis system , to analyze the expression profiles of known mirnas and to predict and study the possible mirna candidates . the differentially expressed mirnas and genes are retrieved together with mirna and target gene annotation , to uncover the biological significance . the known mirnas and possible mirna candidates will be analyzed together with their expression profiles . to aid the processing and data analysis of this method , we constructed a web - based system , named mirna analysis system . the expression profile of known mirnas in submitted sequences were returned and compared with public dataset using fisher s exact test. it also provides tools for the annotations of the predicted mirna candidates .\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "device = torch.device(\"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(output_dir).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "\n",
    "# Generate summary for a test input\n",
    "test_text = sample_text2\n",
    "inputs = tokenizer(test_text, return_tensors=\"pt\", max_length=1024, truncation=True).to(device)\n",
    "summary_ids = model.generate(inputs[\"input_ids\"], max_length=512, min_length=100)\n",
    "\n",
    "print(\"Generated Summary:\")\n",
    "print(tokenizer.decode(summary_ids[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "450b4451-fab8-41e4-939a-61a7edde1a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BigBirdPegasusForConditionalGeneration(\n",
      "  (model): BigBirdPegasusModel(\n",
      "    (shared): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
      "    (encoder): BigBirdPegasusEncoder(\n",
      "      (embed_tokens): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
      "      (embed_positions): BigBirdPegasusLearnedPositionalEmbedding(4096, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-15): 16 x BigBirdPegasusEncoderLayer(\n",
      "          (self_attn): BigBirdPegasusEncoderAttention(\n",
      "            (self): BigBirdPegasusBlockSparseAttention(\n",
      "              (query): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (key): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "              (value): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            )\n",
      "            (output): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (activation_fn): NewGELUActivation()\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "    (decoder): BigBirdPegasusDecoder(\n",
      "      (embed_tokens): BigBirdPegasusScaledWordEmbedding(96103, 1024, padding_idx=0)\n",
      "      (embed_positions): BigBirdPegasusLearnedPositionalEmbedding(4096, 1024)\n",
      "      (layers): ModuleList(\n",
      "        (0-15): 16 x BigBirdPegasusDecoderLayer(\n",
      "          (self_attn): BigBirdPegasusDecoderAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (activation_fn): NewGELUActivation()\n",
      "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (encoder_attn): BigBirdPegasusDecoderAttention(\n",
      "            (k_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (v_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (q_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "            (out_proj): Linear(in_features=1024, out_features=1024, bias=False)\n",
      "          )\n",
      "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
      "    )\n",
      "  )\n",
      "  (lm_head): Linear(in_features=1024, out_features=96103, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Load fine-tuned model\n",
    "device = torch.device(\"cpu\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(output_dir).to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(output_dir)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
